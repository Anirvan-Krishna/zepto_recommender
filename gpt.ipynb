{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         session_id          product_name\n",
      "0  000ed966131fcb96e0efc4ff2b716a3e              beetroot\n",
      "1  000ed966131fcb96e0efc4ff2b716a3e              cucumber\n",
      "2  0013eab657eaf2d82d7f1e13023d95c2                 onion\n",
      "3  0013eab657eaf2d82d7f1e13023d95c2  long shelf life milk\n",
      "4  0013fabde1e543dd541be925266aadbc                 dates\n",
      "session_id      0\n",
      "product_name    0\n",
      "dtype: int64\n",
      "                              session_id product_name\n",
      "count                             345152       345152\n",
      "unique                            165335          396\n",
      "top     27d86d946e6ea6d022f12211d61f8ac7        onion\n",
      "freq                                   9        31196\n",
      "onion               31196\n",
      "cucumber            19083\n",
      "fresh cow milk      18086\n",
      "beetroot            17077\n",
      "gourds              15625\n",
      "                    ...  \n",
      "shringar                1\n",
      "suitcase                1\n",
      "coriander leaves        1\n",
      "moth dal                1\n",
      "cola drinks             1\n",
      "Name: product_name, Length: 396, dtype: int64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'n_users'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m model \u001b[38;5;241m=\u001b[39m SVD()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Evaluate the model using cross-validation\u001b[39;00m\n\u001b[0;32m     63\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(model, dataset, measures\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     64\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:155\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:196\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'n_users'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('session_data.csv')\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Frequency of each product\n",
    "product_freq = data['product_name'].value_counts()\n",
    "print(product_freq)\n",
    "\n",
    "# Collaborative Filtering Setup\n",
    "# Create an implicit rating dataset where if a product is bought in a session, it is considered as a positive interaction\n",
    "# We will use the number of times a product appears in a session as an implicit feedback score\n",
    "# For collaborative filtering, we need to map product names and session ids to integer ids\n",
    "\n",
    "# Create a mapping for session_ids and product_names to unique integer ids\n",
    "session_id_map = {id: idx for idx,\n",
    "                  id in enumerate(data['session_id'].unique())}\n",
    "product_id_map = {name: idx for idx,\n",
    "                  name in enumerate(data['product_name'].unique())}\n",
    "\n",
    "# Add these integer ids to the dataframe\n",
    "data['session_idx'] = data['session_id'].map(session_id_map)\n",
    "data['product_idx'] = data['product_name'].map(product_id_map)\n",
    "\n",
    "# Create the implicit feedback dataset required by Surprise\n",
    "# Since we don't have explicit ratings, we use the count of products bought in a session as implicit feedback\n",
    "# For simplicity, we assign a feedback value of 1 to each transaction\n",
    "\n",
    "# Note: In real-world scenarios, feedback can be scaled based on frequency or other business logic\n",
    "data['feedback'] = 1\n",
    "\n",
    "# Convert the data to Surprise's format\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "dataset = Dataset.load_from_df(\n",
    "    data[['session_idx', 'product_idx', 'feedback']], reader)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "trainset, testset = train_test_split(\n",
    "    dataset.build_full_trainset().build_testset(), test_size=0.2)\n",
    "\n",
    "# Initialize the SVD model\n",
    "model = SVD()\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainset)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, dataset, measures=[\n",
    "                            'RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Display the accuracy metrics\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Generate recommendations for a session\n",
    "\n",
    "\n",
    "def get_recommendations(session_id, num_recommendations=5):\n",
    "    session_idx = session_id_map.get(session_id)\n",
    "    if session_idx is None:\n",
    "        return \"Session ID not found.\"\n",
    "\n",
    "    # All products in the catalog\n",
    "    all_product_idxs = set(product_id_map.values())\n",
    "    products_bought = set(\n",
    "        data[data['session_id'] == session_id]['product_idx'])\n",
    "\n",
    "    # Products not yet bought in the session\n",
    "    products_not_bought = all_product_idxs - products_bought\n",
    "\n",
    "    # Predict the 'feedback' score for products not yet bought\n",
    "    predictions = [model.predict(session_idx, product_idx)\n",
    "                   for product_idx in products_not_bought]\n",
    "\n",
    "    # Sort the predictions by estimated feedback score\n",
    "    recommendations = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    # Get the top N recommendations\n",
    "    recommended_product_idxs = [\n",
    "        pred.iid for pred in recommendations[:num_recommendations]]\n",
    "    recommended_products = [list(product_id_map.keys())[list(\n",
    "        product_id_map.values()).index(idx)] for idx in recommended_product_idxs]\n",
    "\n",
    "    return recommended_products\n",
    "\n",
    "\n",
    "# Example usage: Get recommendations for a specific session\n",
    "session_id_example = '000ed966131fcb96e0efc4ff2b716a3e'\n",
    "recommendations = get_recommendations(session_id_example)\n",
    "print(f'Recommendations for session {session_id_example}: {recommendations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Get recommendations for a specific session\n",
    "session_id_example = '000ed966131fcb96e0efc4ff2b716a3e'\n",
    "recommendations = get_recommendations(session_id_example)\n",
    "print(f'Recommendations for session {session_id_example}: {recommendations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
